{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Daten aus einer CSV-Datei laden\n",
    "FILE_PATH = 'Data/Schnittflaechendaten.csv'\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Die ersten fünf und die elfte Spalte aus den Daten entfernen\n",
    "data = data.drop(data.columns[[0, 1, 2, 3, 4, 11]], axis=1)\n",
    "\n",
    "# Die Daten in Merkmale (X) und Zielwerte (y) aufteilen\n",
    "X = data.iloc[:, :6]  # Die ersten 6 Spalten als Merkmale\n",
    "y = data.iloc[:, 6:]  # Die restlichen Spalten als Zielwerte\n",
    "\n",
    "# Den Maximalwert für jede Spalte in X bestimmen\n",
    "max_values = X.max()\n",
    "\n",
    "# Jede Spalte von X mit ihrem Maximalwert normalisieren\n",
    "X = X.apply(lambda x: x / x.max(), axis=0)\n",
    "\n",
    "# Die Daten in Trainings- und Testdatensätze mit einem Verhältnis von 80:20 aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 374.5240 - mae: 12.5244 - val_loss: 123.4572 - val_mae: 8.0380\n",
      "Epoch 2/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 123.6458 - mae: 7.9949 - val_loss: 120.6125 - val_mae: 8.0216\n",
      "Epoch 3/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 113.5191 - mae: 7.6987 - val_loss: 96.2581 - val_mae: 7.2739\n",
      "Epoch 4/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 60.2384 - mae: 5.5755 - val_loss: 49.0187 - val_mae: 4.9623\n",
      "Epoch 5/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 37.8362 - mae: 4.3954 - val_loss: 32.7686 - val_mae: 4.1859\n",
      "Epoch 6/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 31.0422 - mae: 4.0165 - val_loss: 26.1925 - val_mae: 3.7003\n",
      "Epoch 7/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 26.1954 - mae: 3.7361 - val_loss: 24.2157 - val_mae: 3.5335\n",
      "Epoch 8/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 24.3427 - mae: 3.5809 - val_loss: 20.4758 - val_mae: 3.3046\n",
      "Epoch 9/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 21.2835 - mae: 3.3698 - val_loss: 18.7584 - val_mae: 3.1878\n",
      "Epoch 10/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 19.8701 - mae: 3.2391 - val_loss: 17.6857 - val_mae: 3.0431\n",
      "Epoch 11/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 18.3565 - mae: 3.1143 - val_loss: 18.0890 - val_mae: 3.0502\n",
      "Epoch 12/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 16.7719 - mae: 2.9606 - val_loss: 14.3592 - val_mae: 2.7148\n",
      "Epoch 13/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 15.7426 - mae: 2.8147 - val_loss: 14.1139 - val_mae: 2.7274\n",
      "Epoch 14/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 14.4825 - mae: 2.7211 - val_loss: 12.9208 - val_mae: 2.4924\n",
      "Epoch 15/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 13.0032 - mae: 2.5844 - val_loss: 11.5832 - val_mae: 2.4086\n",
      "Epoch 16/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 12.2966 - mae: 2.4817 - val_loss: 12.3290 - val_mae: 2.4488\n",
      "Epoch 17/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 12.3949 - mae: 2.4921 - val_loss: 10.3350 - val_mae: 2.2407\n",
      "Epoch 18/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 10.7974 - mae: 2.3179 - val_loss: 9.6214 - val_mae: 2.1645\n",
      "Epoch 19/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 10.1626 - mae: 2.2603 - val_loss: 10.2858 - val_mae: 2.2225\n",
      "Epoch 20/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 10.1290 - mae: 2.2443 - val_loss: 8.9234 - val_mae: 2.1133\n",
      "Epoch 21/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 9.6581 - mae: 2.2017 - val_loss: 9.2169 - val_mae: 2.1004\n",
      "Epoch 22/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.8182 - mae: 2.0544 - val_loss: 7.4665 - val_mae: 1.8848\n",
      "Epoch 23/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.3318 - mae: 2.0256 - val_loss: 7.6025 - val_mae: 1.9246\n",
      "Epoch 24/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.1110 - mae: 2.0153 - val_loss: 14.8236 - val_mae: 2.6574\n",
      "Epoch 25/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 8.2151 - mae: 2.0209 - val_loss: 8.0128 - val_mae: 1.8911\n",
      "Epoch 26/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 7.5891 - mae: 1.9294 - val_loss: 6.3789 - val_mae: 1.7253\n",
      "Epoch 27/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.8234 - mae: 1.8091 - val_loss: 6.1951 - val_mae: 1.7294\n",
      "Epoch 28/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 7.0709 - mae: 1.8588 - val_loss: 6.8388 - val_mae: 1.8396\n",
      "Epoch 29/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.8352 - mae: 1.8442 - val_loss: 6.7068 - val_mae: 1.7337\n",
      "Epoch 30/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.3281 - mae: 1.7548 - val_loss: 5.7625 - val_mae: 1.6447\n",
      "Epoch 31/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.3137 - mae: 1.7501 - val_loss: 8.5569 - val_mae: 1.9933\n",
      "Epoch 32/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 6.2248 - mae: 1.7283 - val_loss: 5.7985 - val_mae: 1.6464\n",
      "Epoch 33/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.9701 - mae: 1.6913 - val_loss: 5.3597 - val_mae: 1.5845\n",
      "Epoch 34/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.4965 - mae: 1.6376 - val_loss: 5.2466 - val_mae: 1.5298\n",
      "Epoch 35/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.4251 - mae: 1.6246 - val_loss: 5.8441 - val_mae: 1.6153\n",
      "Epoch 36/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.6800 - mae: 1.6432 - val_loss: 5.6176 - val_mae: 1.6361\n",
      "Epoch 37/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.4217 - mae: 1.6089 - val_loss: 5.4131 - val_mae: 1.6179\n",
      "Epoch 38/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 5.4221 - mae: 1.5830 - val_loss: 4.5297 - val_mae: 1.4338\n",
      "Epoch 39/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.9393 - mae: 1.5334 - val_loss: 4.9955 - val_mae: 1.5343\n",
      "Epoch 40/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.9026 - mae: 1.5231 - val_loss: 5.6561 - val_mae: 1.6117\n",
      "Epoch 41/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.7428 - mae: 1.4997 - val_loss: 4.4095 - val_mae: 1.4198\n",
      "Epoch 42/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.5990 - mae: 1.4784 - val_loss: 4.2549 - val_mae: 1.3836\n",
      "Epoch 43/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.6926 - mae: 1.4940 - val_loss: 4.5891 - val_mae: 1.4561\n",
      "Epoch 44/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.5460 - mae: 1.4541 - val_loss: 4.2014 - val_mae: 1.3630\n",
      "Epoch 45/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.3176 - mae: 1.4318 - val_loss: 4.4306 - val_mae: 1.3692\n",
      "Epoch 46/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.5359 - mae: 1.4643 - val_loss: 5.0322 - val_mae: 1.5077\n",
      "Epoch 47/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.5238 - mae: 1.4520 - val_loss: 5.4449 - val_mae: 1.5738\n",
      "Epoch 48/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.1031 - mae: 1.3969 - val_loss: 4.8825 - val_mae: 1.4846\n",
      "Epoch 49/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.0820 - mae: 1.3962 - val_loss: 6.6712 - val_mae: 1.7119\n",
      "Epoch 50/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.4081 - mae: 1.4316 - val_loss: 4.4794 - val_mae: 1.4022\n",
      "Epoch 51/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.9799 - mae: 1.3699 - val_loss: 4.4171 - val_mae: 1.4099\n",
      "Epoch 52/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.3210 - mae: 1.4098 - val_loss: 4.1812 - val_mae: 1.3769\n",
      "Epoch 53/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.2196 - mae: 1.3931 - val_loss: 5.7315 - val_mae: 1.5453\n",
      "Epoch 54/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.2105 - mae: 1.3831 - val_loss: 4.1167 - val_mae: 1.3665\n",
      "Epoch 55/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.2412 - mae: 1.4023 - val_loss: 5.1165 - val_mae: 1.5707\n",
      "Epoch 56/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.1273 - mae: 1.4073 - val_loss: 6.0674 - val_mae: 1.5775\n",
      "Epoch 57/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8639 - mae: 1.3358 - val_loss: 6.4641 - val_mae: 1.6720\n",
      "Epoch 58/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.2385 - mae: 1.3794 - val_loss: 4.2134 - val_mae: 1.3424\n",
      "Epoch 59/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.0056 - mae: 1.3553 - val_loss: 4.0891 - val_mae: 1.3829\n",
      "Epoch 60/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 4.2931 - mae: 1.3779 - val_loss: 5.4763 - val_mae: 1.5198\n",
      "Epoch 61/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.7575 - mae: 1.3038 - val_loss: 3.8560 - val_mae: 1.2924\n",
      "Epoch 62/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8226 - mae: 1.3188 - val_loss: 5.4660 - val_mae: 1.5625\n",
      "Epoch 63/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.7501 - mae: 1.3140 - val_loss: 6.5025 - val_mae: 1.6504\n",
      "Epoch 64/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.7404 - mae: 1.3048 - val_loss: 6.0066 - val_mae: 1.5941\n",
      "Epoch 65/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8325 - mae: 1.3350 - val_loss: 4.0700 - val_mae: 1.3155\n",
      "Epoch 66/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8320 - mae: 1.3079 - val_loss: 4.7040 - val_mae: 1.4062\n",
      "Epoch 67/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8087 - mae: 1.3059 - val_loss: 4.8683 - val_mae: 1.4572\n",
      "Epoch 68/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8311 - mae: 1.3270 - val_loss: 3.5467 - val_mae: 1.2248\n",
      "Epoch 69/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4563 - mae: 1.2516 - val_loss: 3.4295 - val_mae: 1.2181\n",
      "Epoch 70/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8068 - mae: 1.3160 - val_loss: 4.7250 - val_mae: 1.4398\n",
      "Epoch 71/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5320 - mae: 1.2530 - val_loss: 3.5100 - val_mae: 1.2348\n",
      "Epoch 72/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.7071 - mae: 1.2931 - val_loss: 3.9298 - val_mae: 1.3331\n",
      "Epoch 73/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.7598 - mae: 1.2818 - val_loss: 4.1013 - val_mae: 1.3148\n",
      "Epoch 74/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6952 - mae: 1.2919 - val_loss: 3.9948 - val_mae: 1.2647\n",
      "Epoch 75/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6083 - mae: 1.2684 - val_loss: 3.7457 - val_mae: 1.2981\n",
      "Epoch 76/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6333 - mae: 1.2828 - val_loss: 3.9120 - val_mae: 1.2764\n",
      "Epoch 77/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4827 - mae: 1.2579 - val_loss: 3.6255 - val_mae: 1.2620\n",
      "Epoch 78/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5922 - mae: 1.2753 - val_loss: 3.4014 - val_mae: 1.2389\n",
      "Epoch 79/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4761 - mae: 1.2557 - val_loss: 4.5449 - val_mae: 1.3364\n",
      "Epoch 80/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5132 - mae: 1.2531 - val_loss: 3.7440 - val_mae: 1.2564\n",
      "Epoch 81/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6693 - mae: 1.2719 - val_loss: 3.3585 - val_mae: 1.1932\n",
      "Epoch 82/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6188 - mae: 1.2641 - val_loss: 3.8254 - val_mae: 1.3203\n",
      "Epoch 83/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5810 - mae: 1.2765 - val_loss: 3.6500 - val_mae: 1.2471\n",
      "Epoch 84/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4595 - mae: 1.2564 - val_loss: 3.4900 - val_mae: 1.2492\n",
      "Epoch 85/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3130 - mae: 1.2175 - val_loss: 3.7686 - val_mae: 1.2778\n",
      "Epoch 86/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1682 - mae: 1.2018 - val_loss: 3.2166 - val_mae: 1.1539\n",
      "Epoch 87/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2602 - mae: 1.2060 - val_loss: 3.3600 - val_mae: 1.2054\n",
      "Epoch 88/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5200 - mae: 1.2558 - val_loss: 4.5053 - val_mae: 1.4228\n",
      "Epoch 89/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3697 - mae: 1.2404 - val_loss: 3.6053 - val_mae: 1.2305\n",
      "Epoch 90/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5171 - mae: 1.2563 - val_loss: 4.2833 - val_mae: 1.3010\n",
      "Epoch 91/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4959 - mae: 1.2542 - val_loss: 4.5846 - val_mae: 1.4146\n",
      "Epoch 92/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3311 - mae: 1.2351 - val_loss: 3.4142 - val_mae: 1.1836\n",
      "Epoch 93/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5015 - mae: 1.2602 - val_loss: 3.5099 - val_mae: 1.2573\n",
      "Epoch 94/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1533 - mae: 1.1827 - val_loss: 3.6927 - val_mae: 1.2666\n",
      "Epoch 95/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1290 - mae: 1.1781 - val_loss: 4.0906 - val_mae: 1.3644\n",
      "Epoch 96/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.5841 - mae: 1.2626 - val_loss: 5.1504 - val_mae: 1.5557\n",
      "Epoch 97/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3487 - mae: 1.2015 - val_loss: 4.7725 - val_mae: 1.4925\n",
      "Epoch 98/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1216 - mae: 1.1938 - val_loss: 3.5511 - val_mae: 1.2528\n",
      "Epoch 99/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2792 - mae: 1.2167 - val_loss: 6.6514 - val_mae: 1.7319\n",
      "Epoch 100/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1533 - mae: 1.1865 - val_loss: 3.4508 - val_mae: 1.2051\n",
      "Epoch 101/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1524 - mae: 1.1775 - val_loss: 5.6931 - val_mae: 1.4761\n",
      "Epoch 102/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4667 - mae: 1.2527 - val_loss: 3.7715 - val_mae: 1.2967\n",
      "Epoch 103/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2842 - mae: 1.2035 - val_loss: 3.5891 - val_mae: 1.2441\n",
      "Epoch 104/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2279 - mae: 1.2024 - val_loss: 3.5634 - val_mae: 1.2570\n",
      "Epoch 105/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.6157 - mae: 1.2713 - val_loss: 3.3333 - val_mae: 1.1943\n",
      "Epoch 106/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2734 - mae: 1.2197 - val_loss: 4.0744 - val_mae: 1.2595\n",
      "Epoch 107/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3143 - mae: 1.2110 - val_loss: 3.4115 - val_mae: 1.2079\n",
      "Epoch 108/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1678 - mae: 1.1848 - val_loss: 3.4280 - val_mae: 1.1925\n",
      "Epoch 109/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1084 - mae: 1.1769 - val_loss: 3.3526 - val_mae: 1.1907\n",
      "Epoch 110/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2382 - mae: 1.1989 - val_loss: 3.1981 - val_mae: 1.1745\n",
      "Epoch 111/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1456 - mae: 1.1887 - val_loss: 3.3121 - val_mae: 1.2107\n",
      "Epoch 112/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0737 - mae: 1.1780 - val_loss: 3.8743 - val_mae: 1.2509\n",
      "Epoch 113/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1521 - mae: 1.1970 - val_loss: 3.4758 - val_mae: 1.2260\n",
      "Epoch 114/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2138 - mae: 1.2153 - val_loss: 5.0793 - val_mae: 1.4698\n",
      "Epoch 115/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4550 - mae: 1.2379 - val_loss: 4.2723 - val_mae: 1.3131\n",
      "Epoch 116/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0376 - mae: 1.1520 - val_loss: 3.8463 - val_mae: 1.2938\n",
      "Epoch 117/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1127 - mae: 1.1719 - val_loss: 3.6049 - val_mae: 1.2185\n",
      "Epoch 118/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1604 - mae: 1.1953 - val_loss: 3.6769 - val_mae: 1.2445\n",
      "Epoch 119/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1514 - mae: 1.1765 - val_loss: 3.9784 - val_mae: 1.2970\n",
      "Epoch 120/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3082 - mae: 1.2162 - val_loss: 4.1570 - val_mae: 1.3067\n",
      "Epoch 121/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9336 - mae: 1.1411 - val_loss: 3.1712 - val_mae: 1.1561\n",
      "Epoch 122/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1325 - mae: 1.1649 - val_loss: 3.3085 - val_mae: 1.1637\n",
      "Epoch 123/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0478 - mae: 1.1793 - val_loss: 3.3781 - val_mae: 1.1916\n",
      "Epoch 124/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4329 - mae: 1.2344 - val_loss: 3.9317 - val_mae: 1.2995\n",
      "Epoch 125/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9721 - mae: 1.1662 - val_loss: 3.3410 - val_mae: 1.1681\n",
      "Epoch 126/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.8428 - mae: 1.2836 - val_loss: 3.3702 - val_mae: 1.1921\n",
      "Epoch 127/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.4415 - mae: 1.2498 - val_loss: 3.1546 - val_mae: 1.1405\n",
      "Epoch 128/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9003 - mae: 1.1338 - val_loss: 4.7870 - val_mae: 1.3548\n",
      "Epoch 129/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0356 - mae: 1.1620 - val_loss: 4.4978 - val_mae: 1.4426\n",
      "Epoch 130/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9481 - mae: 1.1497 - val_loss: 3.9451 - val_mae: 1.2709\n",
      "Epoch 131/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1234 - mae: 1.1591 - val_loss: 3.4476 - val_mae: 1.2231\n",
      "Epoch 132/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0644 - mae: 1.1437 - val_loss: 4.0502 - val_mae: 1.3021\n",
      "Epoch 133/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1090 - mae: 1.1740 - val_loss: 3.2806 - val_mae: 1.2124\n",
      "Epoch 134/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0830 - mae: 1.1697 - val_loss: 3.4529 - val_mae: 1.2214\n",
      "Epoch 135/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.8494 - mae: 1.1165 - val_loss: 3.6776 - val_mae: 1.2319\n",
      "Epoch 136/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0318 - mae: 1.1655 - val_loss: 3.6113 - val_mae: 1.2546\n",
      "Epoch 137/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.8276 - mae: 1.1297 - val_loss: 5.3313 - val_mae: 1.5356\n",
      "Epoch 138/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.2860 - mae: 1.2050 - val_loss: 3.8778 - val_mae: 1.2878\n",
      "Epoch 139/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.3027 - mae: 1.2108 - val_loss: 4.2304 - val_mae: 1.3555\n",
      "Epoch 140/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.8975 - mae: 1.1469 - val_loss: 4.5115 - val_mae: 1.3700\n",
      "Epoch 141/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0764 - mae: 1.1784 - val_loss: 3.3642 - val_mae: 1.1891\n",
      "Epoch 142/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9992 - mae: 1.1479 - val_loss: 5.0489 - val_mae: 1.5047\n",
      "Epoch 143/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.0475 - mae: 1.1649 - val_loss: 3.6957 - val_mae: 1.2401\n",
      "Epoch 144/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9937 - mae: 1.1423 - val_loss: 3.5894 - val_mae: 1.2635\n",
      "Epoch 145/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.8526 - mae: 1.1297 - val_loss: 3.6826 - val_mae: 1.2306\n",
      "Epoch 146/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9600 - mae: 1.1600 - val_loss: 3.3883 - val_mae: 1.2080\n",
      "Epoch 147/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1179 - mae: 1.1752 - val_loss: 4.3837 - val_mae: 1.2960\n",
      "Epoch 148/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 3.1058 - mae: 1.1707 - val_loss: 3.2019 - val_mae: 1.1706\n",
      "Epoch 149/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.9741 - mae: 1.1584 - val_loss: 3.4122 - val_mae: 1.2116\n",
      "Epoch 150/150\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 2.8321 - mae: 1.1243 - val_loss: 4.0496 - val_mae: 1.3296\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0496 - mae: 1.3296\n",
      "Test loss: 4.049628257751465, Test MAE: 1.3295562267303467\n"
     ]
    }
   ],
   "source": [
    "# Modell definieren\n",
    "# Das Modell besteht aus mehreren Schichten (Layers), darunter Eingabeschicht, versteckte Schichten und Ausgabeschicht\n",
    "model = Sequential([\n",
    "    Input(shape=(6,)),  # Eingabeschicht mit 6 Eingabe-Features\n",
    "    Dense(40, activation='relu'),  # Erste versteckte Schicht mit 40 Neuronen und ReLU-Aktivierungsfunktion\n",
    "    Dense(50, activation='relu'),  # Zweite versteckte Schicht mit 50 Neuronen und ReLU-Aktivierungsfunktion\n",
    "    Dense(50, activation='relu'),  # Dritte versteckte Schicht mit 50 Neuronen und ReLU-Aktivierungsfunktion\n",
    "    Dense(45, activation='relu'),  # Vierte versteckte Schicht mit 45 Neuronen und ReLU-Aktivierungsfunktion\n",
    "    Dense(4, activation='linear')  # Ausgabeschicht mit 4 Neuronen und linearer Aktivierungsfunktion\n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "# Verlustfunktion: Mean Squared Error (MSE)\n",
    "# Optimierungsalgorithmus: Adam\n",
    "# Metrik: Mean Absolute Error (MAE)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Anlernprozess mittels History-Moduls aufzeichnen\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "# Modell trainieren\n",
    "# Trainingsdaten: X_train und y_train\n",
    "# Validierungsdaten: X_test und y_test\n",
    "# Epochen: 150\n",
    "# Batch-Größe: 4\n",
    "# Callback: History-Modul zur Aufzeichnung des Trainingsverlaufs\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=4, validation_data=(X_test, y_test), callbacks=[history])\n",
    "\n",
    "# Modell auf dem Testdatensatz evaluieren\n",
    "# Verlust (Loss) und mittlerer absoluter Fehler (MAE) werden berechnet\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}, Test MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des trainierten Modells\n",
    "# Das Modell wird in einer Datei mit dem Namen 'model.keras' gespeichert.\n",
    "# Dies ermöglicht es, das Modell später wieder zu laden und erneut zu verwenden, ohne es erneut trainieren zu müssen.\n",
    "#model.save('Model/model2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Risse_und_Wilke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
